{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78541602",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9941908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocessing.time_series_preprocessing import get_dengue_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from epiweeks import Week\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1339aa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_dengue_dataset(labels_path='../Tabular_data/dengue_tabular.csv', embeddings_path=None, municipality='Neiva')\n",
    "\n",
    "labels = labels.reset_index()\n",
    "labels.rename(columns={'index': 'Date'}, inplace=True)\n",
    "\n",
    "labels = labels[(labels['Date'] > 201552) & (labels['Date'] < 201901)]\n",
    "\n",
    "labels['Date'] = labels['Date'].apply(lambda x: Week.fromstring(str(x)).enddate())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85966273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the time series of given dataframe\n",
    "plt.plot(labels.Date, labels.Labels)\n",
    " \n",
    "# Giving title to the chart using plt.title\n",
    "plt.title('Classes by Date')\n",
    " \n",
    "# rotating the x-axis tick labels at 30degree\n",
    "# towards right\n",
    "plt.xticks(rotation=30, ha='right')\n",
    "\n",
    "# Providing x and y label to the chart\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48518af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind_from_stats\n",
    "\n",
    "mean1 = 115.853\n",
    "std1 = 8.798\n",
    "n1 = 5\n",
    "\n",
    "mean2 = 100.988\n",
    "std2 = 0.795\n",
    "n2 = 5\n",
    "\n",
    "tstat, pvalue = ttest_ind_from_stats(mean1, std1, n1, mean2, std2, n2)\n",
    "pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6cc493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f57e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab970aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deb3207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Attention, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "n_features = 10\n",
    "\n",
    "# Define the inpu\n",
    "input_seq = Input(shape=(None, n_features))  # Input shape: (batch_size, sequence_length, n_features)\n",
    "\n",
    "# Define the LSTM layer and get the output sequence\n",
    "lstm_output = LSTM(64, return_sequences=True)(input_seq)  # Output shape: (batch_size, sequence_length, 64)\n",
    "\n",
    "# Apply attention to the LSTM output sequence\n",
    "attention_output = Attention()([lstm_output, lstm_output])  # Output shape: (batch_size, 64)\n",
    "\n",
    "pool_output = GlobalAveragePooling1D()(attention_output)\n",
    "\n",
    "# Add a dense layer and output layer\n",
    "output = Dense(1, activation='sigmoid')(pool_output)  # Output shape: (batch_size, 1)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_seq, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2c66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5228126b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88901f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the input layer\n",
    "input_seq = Input(shape=(None, n_features))  # Input shape: (batch_size, sequence_length, n_features)\n",
    "\n",
    "# Define the Transformer encoder layer\n",
    "encoder_output = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=64)(input_seq, input_seq)\n",
    "# Encoder output shape: (batch_size, sequence_length, hidden_size)\n",
    "encoder_output = tf.keras.layers.Dropout(0.1)(encoder_output)\n",
    "encoder_output = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoder_output)\n",
    "\n",
    "# Apply a feed-forward neural network to the output of the Transformer encoder\n",
    "ffn_output = tf.keras.layers.Dense(64, activation='relu')(encoder_output)\n",
    "# FNN output shape: (batch_size, sequence_length, 64)\n",
    "ffn_output = tf.keras.layers.Dense(32, activation='relu')(ffn_output)\n",
    "\n",
    "pool_output = GlobalAveragePooling1D()(ffn_output)\n",
    "\n",
    "# FNN output shape: (batch_size, sequence_length, 32)\n",
    "ffn_output = tf.keras.layers.Dropout(0.1)(pool_output)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(1, activation='sigmoid')(ffn_output)  # Output shape: (batch_size, 1)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=input_seq, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14cf27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999b8d22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a78764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8b1acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_black(image):\n",
    "    \n",
    "    black_pixels = np.count_nonzero(image==0)\n",
    "    #print(black_pixels)\n",
    "    pixels = image.shape[0] * image.shape[1] * image.shape[2]\n",
    "    \n",
    "    if black_pixels == pixels:\n",
    "        #print('The image is black')\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a2c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde84d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Read Dataset:\"\"\"\n",
    "path = '../Dataset_10_best_cities/'\n",
    "\n",
    "for municipality in os.listdir(path):\n",
    "    count = 0\n",
    "    municipality_path = os.path.join(path, municipality)\n",
    "    for image_name in os.listdir(municipality_path):\n",
    "        image_path = os.path.join(municipality_path, image_name)\n",
    "        # Skip directory\n",
    "        if os.path.isdir(image_path):\n",
    "            #print(f'Directory: {image_path}')\n",
    "            continue\n",
    "        image = io.imread(image_path)\n",
    "        is_black = count_black(image)\n",
    "        if is_black:\n",
    "            count += 1\n",
    "        \n",
    "    print(f'The number of black images for {municipality} are: {count}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b431aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Read Dataset:\"\"\"\n",
    "path = '../FULL_COLOMBIA_v2/'\n",
    "\n",
    "for municipality in os.listdir(path):\n",
    "    count = 0\n",
    "    municipality_path = os.path.join(path, municipality)\n",
    "    for image_name in os.listdir(municipality_path):\n",
    "        image_path = os.path.join(municipality_path, image_name)\n",
    "        # Skip directory\n",
    "        if os.path.isdir(image_path):\n",
    "            #print(f'Directory: {image_path}')\n",
    "            continue\n",
    "        image = io.imread(image_path)\n",
    "        is_black = count_black(image)\n",
    "        if is_black:\n",
    "            count += 1\n",
    "        \n",
    "    print(f'The number of black images for {municipality} are: {count}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3211332c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71de4c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b22a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac7699d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b465df0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77b10a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-cv\n",
    "from keras_cv.models import ViTTiny16\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b3b8e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(224, 224, 3))\n",
    "\n",
    "vit = ViTTiny16(\n",
    "        include_rescaling=False,\n",
    "        include_top=False,\n",
    "        name=\"ViTTiny32\",\n",
    "        weights=\"imagenet\",\n",
    "        input_tensor=inputs,\n",
    "        pooling=\"token_pooling\",\n",
    "        activation=tf.keras.activations.gelu,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da02832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4beb95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfe9957d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You do not have pycocotools installed, so KerasCV pycoco metrics are not available. Please run `pip install pycocotools`.\n",
      "You do not have pyococotools installed, so the `PyCOCOCallback` API is not available.\n",
      "You do not have Waymo Open Dataset installed, so KerasCV Waymo metrics are not available.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7ef86c5b6d90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from Models.Pretrained_DL_Models import get_backbone\n",
    "\n",
    "backbone = 'ConvNeXtTiny' # 'ViT' # 'ConvNeXtTiny' # 'ConvNeXtSmall' # 'ConvNeXtBase' # 'ResNet50V2' # 'VGG16' # 'MobileNetV2'\n",
    "weights = 'imagenet' # 'imagenet' # None # 'sentinel_vae' # 'sentinel_ae'\n",
    "freeze = False\n",
    "cnn_base = get_backbone(target_size=(224, 224, 3), backbone=backbone, freeze=True, weights=weights)\n",
    "cnn_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c4d76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " convnext_tiny (Functional)  (None, 7, 7, 768)         27820128  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 768)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,820,128\n",
      "Trainable params: 0\n",
      "Non-trainable params: 27,820,128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e047198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed (TimeDistr  (None, 3, 768)           27820128  \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " time_distributed_1 (TimeDis  (None, 3, 1024)          787456    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 3, 120)            549600    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,157,184\n",
      "Trainable params: 1,337,056\n",
      "Non-trainable params: 27,820,128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.TimeDistributed(cnn_base, input_shape = ((3,) + (224, 224, 3))))\n",
    "#model.add(tf.keras.layers.TimeDistributed(Flatten()))\n",
    "model.add(tf.keras.layers.TimeDistributed(Dense(1024)))\n",
    "model.add(tf.keras.layers.LSTM(120, dropout=0.1, return_sequences=True))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8429b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261dc72f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow28_p38_gpu_v1]",
   "language": "python",
   "name": "conda-env-tensorflow28_p38_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
