{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b37830c",
   "metadata": {},
   "source": [
    "# Setup Enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "324883c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocessing.selfsupervised_data_praparation import plot_samples, get_dataset_list\n",
    "from Preprocessing.generate_embeddings import generate_embeddings_df, save_embeddings_as_csv\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.applications import MobileNetV2, VGG16, ResNet50V2\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b25238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Dataset\n",
    "path = '../Dataset_10_best_cities/'\n",
    "model_name = 'variational_autoencoder' #'VGG16' #'MobileNetV2' # 'vit' # 'autoencoder' #'variational_autoencoder'\n",
    "latent_dim = 1024\n",
    "\n",
    "target_size = (224, 224, 1)\n",
    "model_input = (224, 224, 3)\n",
    "\n",
    "# Model path\n",
    "model_path = f'Weights/{model_name}_{target_size[0]}_{latent_dim}.h5'  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cda6f6",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a436bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_samples(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf8fe2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in directories: \n",
      "54001\n",
      "41001\n",
      "5001\n",
      "50001\n",
      "68001\n",
      "8001\n",
      "23001\n",
      "76001\n",
      "73001\n",
      "5360\n"
     ]
    }
   ],
   "source": [
    "image_list = get_dataset_list(path, show_dirs=True, head=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68146976",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "107f8d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/datascience/conda/generalml_p37_gpu_v1/lib/python3.7/site-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-05 18:24:09.421862: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-03-05 18:24:09.422039: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-03-05 18:24:09.422122: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (9f7bdfccc75e): /proc/driver/nvidia/version does not exist\n",
      "2023-03-05 18:24:12.288172: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model (Functional)           (None, 1024)              524389312 \n",
      "=================================================================\n",
      "Total params: 524,389,312\n",
      "Trainable params: 0\n",
      "Non-trainable params: 524,389,312\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "if model_name == 'variational_autoencoder':\n",
    "    from Models import Variational_Autoencoder\n",
    "    model = Variational_Autoencoder.get_Variational_Autoencoder(model_path=model_path, backbone=True, target_size = model_input, latent_dim = latent_dim, lr=0.0001)\n",
    "elif model_name == 'autoencoder':\n",
    "    from Models import Autoencoder\n",
    "    model = Autoencoder.get_Autoencoder(model_path=model_path, backbone=True, target_size = model_input, latent_dim = latent_dim)\n",
    "elif model_name == 'vit':\n",
    "    from Models import ViT\n",
    "    model = ViT.get_vit_backbone(model_input)\n",
    "elif model_name == 'MobileNetV2':\n",
    "    cnn = MobileNetV2(input_shape=model_input, include_top=False, weights='imagenet')\n",
    "elif model_name == 'VGG16': # min depth\n",
    "    cnn = VGG16(input_shape=model_input, include_top=False, weights='imagenet')\n",
    "elif model_name == 'ResNet50V2':\n",
    "    cnn = ResNet50V2(input_shape=model_input, include_top=False, weights='imagenet') \n",
    "\n",
    "if model_name in ['MobileNetV2', 'VGG16', 'ResNet50V2']:\n",
    "    model = Sequential()\n",
    "    model.add(cnn)\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # freeze:\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a56f31c",
   "metadata": {},
   "source": [
    "## Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90a5637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Embeddings for the band 1 with the model variational_autoencoder...\n",
      "Done!\n",
      "Generating Embeddings for the band 2 with the model variational_autoencoder...\n",
      "Done!\n",
      "Generating Embeddings for the band 3 with the model variational_autoencoder...\n",
      "Done!\n",
      "Generating Embeddings for the band 4 with the model variational_autoencoder...\n",
      "Done!\n",
      "Generating Embeddings for the band 5 with the model variational_autoencoder...\n",
      "Done!\n",
      "Generating Embeddings for the band 6 with the model variational_autoencoder...\n",
      "Done!\n",
      "Generating Embeddings for the band 7 with the model variational_autoencoder...\n",
      "Done!\n",
      "Generating Embeddings for the band 8 with the model variational_autoencoder...\n"
     ]
    }
   ],
   "source": [
    "for band in range(12):\n",
    "    if band+1 < 5:\n",
    "        print(f'Generating Embeddings for the band {band+1} with the model {model_name}...')\n",
    "        print('Done!')\n",
    "        continue\n",
    "    print(f'Generating Embeddings for the band {band+1} with the model {model_name}...')\n",
    "    # Embeddings path\n",
    "    embeddings_path = f'Embeddings/{model_name}_Per_Band/{target_size[0]}_band{band+1}.csv'\n",
    "    # Generate Embeddings\n",
    "    embeddings = generate_embeddings_df(image_list=image_list, model=model, target_size=target_size, BAND=band)\n",
    "    # Save Embeddings\n",
    "    save_embeddings_as_csv(df=embeddings, path=embeddings_path)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6dc365",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3159117c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
