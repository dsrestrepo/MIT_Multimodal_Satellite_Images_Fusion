{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69521487",
   "metadata": {},
   "source": [
    "# Setup Enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716899c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 19:10:09.942389: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-24 19:10:09.980537: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-24 19:10:09.981833: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-24 19:10:10.777450: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from Preprocessing.selfsupervised_data_praparation import plot_samples, get_dataset_list\n",
    "from Preprocessing.generate_embeddings import generate_embeddings_df, save_embeddings_as_csv\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.applications import MobileNetV2, VGG16, ResNet50V2\n",
    "from tensorflow.keras.applications.convnext import ConvNeXtBase, ConvNeXtSmall, ConvNeXtTiny\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0733009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to Dataset\n",
    "path = '../FULL_COLOMBIA_v2/'\n",
    "ignore_black = False\n",
    "\n",
    "model_name = 'variational_autoencoder' #'VGG16' #'MobileNetV2' # 'vit' # 'autoencoder' #'variational_autoencoder' # 'ResNet50V2' #'ConvNeXtTiny'\n",
    "encoder_backbone = 'ResNet50V2' # 'vit' # 'ResNet50V2' # 'ConvNeXtTiny'\n",
    "latent_dim = 1024\n",
    "\n",
    "target_size = (224, 224, 3)\n",
    "model_input = (224, 224, 3)\n",
    "band = 9 #None\n",
    "\n",
    "# Model path _full_dataset\n",
    "if target_size[2] != 1:\n",
    "    model_path = f'Weights/{model_name}_{encoder_backbone}_{target_size[0]}_{latent_dim}_{target_size[2]}Bands_full_dataset.h5' \n",
    "else:\n",
    "    model_path = f'Weights/{model_name}_{encoder_backbone}_{target_size[0]}_{latent_dim}_3Bands_full_dataset.h5' \n",
    "\n",
    "if target_size[2] == 1:\n",
    "    # Embeddings path\n",
    "    if model_name in ['autoencoder', 'variational_autoencoder']:\n",
    "        embeddings_path = f'Embeddings/{model_name}/{model_name}_{encoder_backbone}_Per_Band/{target_size[0]}_band{band+1}.csv'\n",
    "    else:\n",
    "        embeddings_path = f'Embeddings/{model_name}_Per_Band/{target_size[0]}_band{band+1}.csv'\n",
    "else:\n",
    "    # Embeddings path\n",
    "    if model_name in ['autoencoder', 'variational_autoencoder']:\n",
    "        embeddings_path = f'Embeddings/{model_name}/{model_name}_{encoder_backbone}__{target_size[0]}_{latent_dim}_{target_size[2]}Bands.csv'\n",
    "    else:\n",
    "        embeddings_path = f'Embeddings/{model_name}_{target_size[0]}_{latent_dim}.csv'\n",
    "        \n",
    "if ignore_black:\n",
    "    embeddings_path = embeddings_path.replace(\".csv\", \"_no_black_images.csv\")    \n",
    "    \n",
    "if 'FULL' in path:\n",
    "    embeddings_path = embeddings_path.replace(\".csv\", \"_full_dataset.csv\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8cc4a5",
   "metadata": {},
   "source": [
    "## Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd58b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_samples(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49111f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images in directories: \n",
      "76400\n",
      "50573\n",
      "41020\n",
      "85001\n",
      "47288\n",
      "73268\n",
      "68307\n",
      "95001\n",
      "54874\n",
      "76834\n",
      "5088\n",
      "68547\n",
      "73443\n",
      "50313\n",
      "68081\n",
      "44430\n",
      "23855\n",
      "41001\n",
      "86320\n",
      "73408\n",
      "47001\n",
      "86865\n",
      "68406\n",
      "13244\n",
      "25290\n",
      "76892\n",
      "5837\n",
      "73585\n",
      "76109\n",
      "68001\n",
      "15480\n",
      "81736\n",
      "66001\n",
      "5679\n",
      "25488\n",
      "76147\n",
      "68655\n",
      "18753\n",
      "5490\n",
      "8001\n",
      "23555\n",
      "23001\n",
      "73675\n",
      "50006\n",
      "76111\n",
      "20001\n",
      "20011\n",
      "5079\n",
      "5266\n",
      "15469\n",
      "18001\n",
      "95025\n",
      "68679\n",
      "76364\n",
      "73319\n",
      "15753\n",
      "54405\n",
      "8758\n",
      "5360\n",
      "73449\n",
      "41298\n",
      "5212\n",
      "20710\n",
      "73411\n",
      "13430\n",
      "23466\n",
      "25307\n",
      "68276\n",
      "25245\n",
      "76520\n",
      "20013\n",
      "54498\n",
      "5045\n",
      "66170\n",
      "70001\n",
      "86568\n",
      "85010\n",
      "41396\n",
      "41551\n",
      "13688\n",
      "5656\n"
     ]
    }
   ],
   "source": [
    "image_list = get_dataset_list(path, ignore_black=ignore_black, show_dirs=True, head=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4e4648",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953ada7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/datascience/conda/tensorflow28_p38_gpu_v1/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-24 19:10:16.413119: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
      "2023-07-24 19:10:16.662152: W tensorflow/c/c_api.cc:300] Operation '{name:'conv5_block3_2_conv/kernel/Assign' id:3389 op device:{requested: '', assigned: ''} def:{{{node conv5_block3_2_conv/kernel/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](conv5_block3_2_conv/kernel, conv5_block3_2_conv/kernel/Initializer/stateless_random_uniform)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
      "2023-07-24 19:10:22.807205: W tensorflow/c/c_api.cc:300] Operation '{name:'log_variance/bias/Assign' id:6218 op device:{requested: '', assigned: ''} def:{{{node log_variance/bias/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](log_variance/bias, log_variance/bias/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (Functional)          (None, 1024)              27761152  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,761,152\n",
      "Trainable params: 0\n",
      "Non-trainable params: 27,761,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(0)\n",
    "\n",
    "if model_name == 'variational_autoencoder':\n",
    "    from Models import Variational_Autoencoder\n",
    "    model = Variational_Autoencoder.get_Variational_Autoencoder(model_path=model_path, backbone=True, target_size = model_input, latent_dim = latent_dim, lr=0.0001, encoder_backbone=encoder_backbone)\n",
    "elif model_name == 'autoencoder':\n",
    "    from Models import Autoencoder\n",
    "    model = Autoencoder.get_Autoencoder(model_path=model_path, backbone=True, target_size = model_input, latent_dim = latent_dim, encoder_backbone=encoder_backbone)\n",
    "elif model_name == 'vit':\n",
    "    from Models import ViT\n",
    "    model = ViT.get_vit_backbone(model_input)\n",
    "elif model_name == 'MobileNetV2':\n",
    "    cnn = MobileNetV2(input_shape=model_input, include_top=False, weights='imagenet')\n",
    "elif model_name == 'VGG16': # min depth\n",
    "    cnn = VGG16(input_shape=model_input, include_top=False, weights='imagenet')\n",
    "elif model_name == 'ResNet50V2':\n",
    "    cnn = ResNet50V2(input_shape=model_input, include_top=False, weights='imagenet') \n",
    "elif model_name == 'ConvNeXtTiny':\n",
    "    cnn = ConvNeXtTiny(input_shape=model_input, include_top=False, weights='imagenet')  \n",
    "\n",
    "if model_name in ['MobileNetV2', 'VGG16', 'ResNet50V2', 'ConvNeXtTiny']:\n",
    "    model = Sequential()\n",
    "    model.add(cnn)\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "\n",
    "    # freeze:\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ffaa4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from huggingface_hub import push_to_hub_keras\n",
    "\n",
    "#from huggingface_hub import push_to_hub_keras\n",
    "#push_to_hub_keras(model, 'MITCriticalData/Sentinel-2_ConvNeXtTiny_Autoencoder_RGB_full_Colombia_Dataset', create_pr=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96555d2b",
   "metadata": {},
   "source": [
    "## Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c99532",
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_size[2] == 1:\n",
    "    embeddings = generate_embeddings_df(image_list=image_list, model=model, target_size=target_size, BAND=band)\n",
    "else:\n",
    "    embeddings = generate_embeddings_df(image_list=image_list, model=model, target_size=target_size)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a3e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_embeddings_as_csv(df=embeddings, path=embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052df5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075820ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow28_p38_gpu_v1]",
   "language": "python",
   "name": "conda-env-tensorflow28_p38_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
